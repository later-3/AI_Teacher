下面给你一份 **完整、可直接给团队执行的 MVP 文档**。
它包含你要求的：

* **背景（Background）**
* **目的（Goals）**
* **用户故事（User Stories）**（包含你要求的 *逻辑性 + 真实用户体验 + 你举例那种互动式教学*）
* **技术方案（Technical Approach）**
* **开发步骤（Implementation Steps）**（充分考虑前后依赖，任务拆解细粒度）

整个文档结构严谨，条理清晰，可以作为 PRD + 技术设计的合体文档使用。

---

# 📝 **AI Teacher（互动式教学）—— MVP 文档 v1.2**

## 📌 目录

1. 背景
2. 目的
3. 用户故事
4. 技术方案
5. 开发步骤（任务拆解）
6. 后续扩展

---

# 1. 背景（Background）

当前大量学习依赖 B 站、YouTube 等平台的公开课，但存在严重痛点：

1. **无法互动**：视频是单向的，无法像真实课堂一样与老师对话。
2. **碎片化学习困难**：想学某个知识点时很难定位视频时间点。
3. **缺少结构化教学路径**：用户不清楚应该按照什么顺序学习。
4. **理解困难，没有反馈**：用户听不懂时，没有老师即时解释。
5. **传统 AI 只能 Q&A，不会教学**：不会主动讲、不会组织知识结构、不会问问题。

因此，我们需要一个 **AI 交互式教师（AI Teacher）**：

* 能从公开课内容中学习
* 能按小节组织知识
* 能主动教学
* 能自然互动
* 用户可随时提问
* 音频 + 文本双输出
* 本地向量模型（自主部署、低成本、未来兼容边缘设备）

MVP 要验证：
**AI Teacher 能否在完成“知识→结构→互动教学”的闭环后，提供真实有效的学习体验。**

---

# 2. 目的（Goals）

## 🎯 核心目的（MVP 必须完成）

1. **课程知识构建**

   * 支持从 B 站 / YouTube 下载多节课程视频
   * 提取音频、ASR转文字
   * 用户上传 PPT
   * 自动把课程拆成“多个知识小节”（sections）

2. **互动式教学**

   * AI Teacher 能按用户选择的小节进行讲解
   * 先完整讲一个知识点，再进行理解检查（不是一句讲一段就停）
   * 能根据用户回答进行补充解释或继续讲解
   * 用户可随时提问（通过“老师，”触发）

3. **RAG 检索**

   * 全量课程内容向量化
   * 支持按小节过滤检索
   * 提问基于课程资料回答（不幻觉）

4. **本地向量模型部署（Qwen3-Embedding-0.6B）**

   * 作为独立服务对主后端提供 `/embed` 接口
   * 为未来边缘部署做基础

5. **前端交互界面**

   * 对话式学习
   * 可选小节
   * 文本 + 音频播放
   * 显示引用的知识来源

---

# 3. 用户故事（User Stories）

## 🧑‍🎓 用户故事 1：选择学习内容（按小节或自然语言）

**作为用户**
我希望能快速进入我想学的知识点，而不需要从头观看整节视频。

**场景示例：**

* 我在首页看到课程大纲，可点选某个小节，例如“2.3 梯度下降直觉”
* 或者输入：“老师，我想学一下损失函数怎么理解”
* AI Teacher 会自动跳到对应知识点，并开始讲解

**用户价值：** 自主选择学习路径，摆脱顺序强制。

---

## 🧑‍🎓 用户故事 2：AI Teacher 的“完整知识点讲解 + 理解互动”

**作为用户**
我希望 AI Teacher 的讲课方式既自然又有效，不是讲两句就停，而是在：

* **完整讲完一个知识点（一个逻辑完整的小节）后**
* 再提出一个或两个和该知识点强相关的理解检查问题
* 问题不是“懂了吗？”，而是有教育意义，能判断我是否理解
* 然后根据我的回答动态调整讲解深度
* 再继续向下讲

**完整流程示例：**

AI Teacher：

> 接下来我们讲“损失函数的直观理解”。
> 假设你在调节一个模型，你需要知道它到底好不好……
> （完整讲 1–2 段，逻辑连贯，不中断）
>
> 我问你一个小问题：
> 如果损失函数越小代表模型越好，那损失函数为 0 又说明了什么？

用户：

> 应该表示模型预测完全正确？

AI Teacher：

> 很好！
> 你抓住核心概念了。
> 接下来我们进入下一部分：均方误差的推导……

**用户价值：**
学习体验类似“真实老师在讲”，且能确认是否学会。

---

## 🧑‍🎓 用户故事 3：用户随时提问（通过触发词）

**作为用户**
当我突然听不懂时，我希望随时插话提问，而不是等老师讲完。

**触发方式：**

* 以“老师，”开头
* 或“Teacher,” / “老师我问一下”

**示例：**

用户：

> 老师，我不太理解学习率太大为什么会发散？

AI Teacher：

> 好，先暂停一下我们刚才的小节，我来解释这个问题……
> （回答后）
>
> 我们回到刚才的内容，继续讲下一部分。

**用户价值：**
获得即时反馈，不会因为听不懂而卡住。

---

## 🧑‍🎓 用户故事 4：音频学习（播客式）

**作为用户**
我希望 AI Teacher 的讲解能生成音频，方便我边走路边听。

AI Teacher：

> （文字讲解）
> （音频播放按钮）

**用户价值：**
碎片化学习场景增强。

---

# 4. 技术方案（Technical Approach）

技术方案与开发步骤强关联，因此我将技术拆入任务流程中。

核心技术模块：

1. **课程 Ingestion（视频 → 音频 → ASR → 文本 + PPT）**
2. **本地向量服务（Qwen3-Embedding-0.6B）**
3. **向量库（Chroma）**
4. **RAG 检索器（按小节过滤）**
5. **教学引擎（Teaching Engine）**
6. **TTS 引擎**
7. **前端 Web（Streamlit/Gradio）**

---

# 5. 开发步骤（Implementation Steps）

每一步都考虑了前后依赖、任务拆分、可交付物。

---

## 🟦 **Step 1：搭建项目基础结构**（0.5 天）

* 创建 mono-repo（或前后端分离）
* 目录建议：

```
/backend
/embedding_service
/frontend
/data
/vector_db
```

可交付物：基础工程目录 + README

---

## 🟦 **Step 2：课程 Ingestion 管道（2–3 天）**

### 任务 2.1 - 视频下载

* 使用 `yt-dlp` 支持 B站/YouTube
* 输入：课程多个 URL
* 输出：`lecture_x.mp3`

### 任务 2.2 - ASR（Whisper/Faster-Whisper）

* 输出：带时间戳的文本片段 `transcript.json`

### 任务 2.3 - PPT 解析

* 用户上传 `.pptx`
* 使用 `python-pptx` 提取文本 → `slides.json`

### 任务 2.4 - 自动分小节（sectioning）

规则（MVP）：

* 每段 ASR 2–4 分钟 ↔ 一个小节
* 每页 PPT ↔ 一个知识点补充
* 输出统一格式：

```json
{
  "course_id": 1,
  "lecture": 2,
  "section": 3,
  "text": "……",
  "type": "audio" | "ppt"
}
```

可交付物：`/data/sections.json`

---

## 🟦 **Step 3：本地向量服务（1 天）**

### 任务 3.1 - 下载模型

Qwen3-Embedding-0.6B

### 任务 3.2 - 建立 FastAPI 服务

接口：

```
POST /embed
{
  "texts": [...]
}
```

响应：

```
{
  "vectors": [[...], ...]
}
```

可交付物：
`embedding_service/app.py` + 启动脚本

---

## 🟦 **Step 4：构建向量库（Chroma）（1 天）**

### 任务 4.1 - 读取 sections.json

### 任务 4.2 - 调用 /embed 生成向量

### 任务 4.3 - 存入 Chroma

* 支持 metadata filters：lecture、section
* 输出：`/vector_db/`

可交付物：初始化向量库脚本

---

## 🟦 **Step 5：RAG 引擎（1–2 天）**

### 任务 5.1 - 检索

* `retriever(query, filter={lecture:x, section:y})`

### 任务 5.2 - RAG Prompting

Prompt 需包含：

* 你是一名老师
* 回答必须基于资料，不编造
* 风格口语化，适合理解

### 任务 5.3 - 输出引用 metadata

可交付物：
`backend/rag.py`

---

## 🟦 **Step 6：Teaching Engine（教学引擎核心）（3 天）**

这是重点模块。

### 任务 6.1 - 用户意图识别

分类三类：

1. 小节选择（“第二节”“讲损失函数”）
2. 提问（前缀触发）
3. 反馈 / 继续（“继续”“懂了”）

### 任务 6.2 - 完整知识点讲解

执行流程：

1. 从向量库取出该 section 的 top chunks
2. LLM 生成 **一段完整讲解**（不被打断）
3. 生成理解检查问题（1–2 个）

### 任务 6.3 - 互动逻辑

根据用户回答：

| 回答类型 | 行为                 |
| ---- | ------------------ |
| 正确   | 继续下一个知识点           |
| 部分正确 | 补充解释，再继续           |
| 错误   | 换个方式解释             |
| “继续” | 直接跳过提问             |
| 用户提问 | 转 RAG → 回答 → 回到教学点 |

### 任务 6.4 - 返回结构

统一格式：

```json
{
  "text": "讲解内容…",
  "audio_url": "",
  "next_state": {...},
  "references": [...]
}
```

可交付物：
`backend/teaching_engine.py`

---

## 🟦 **Step 7：TTS 服务（0.5–1 天）**

* 使用 edge-tts（local）
* 将讲解 / 回答转为音频
* 前端可直接播放

---

## 🟦 **Step 8：前端实现（1–2 天）**

使用 Streamlit/Gradio：

### 功能：

* 对话框
* 小节选择菜单
* 音频播放器
* 展示引用的 PPT 页面
* 对话轮播（AI Teacher ↔ 学生）

可交付物：
`frontend/app.py`

---

## 🟦 **Step 9：整合与测试（0.5–1 天）**

* 整体流程联调
* 测试教学连贯性
* 测试提问中断与恢复
* 测试小节跳转
* 测试音频播放
* 测试 RAG 回答可靠性

---

# 6. 后续扩展（Post-MVP）

* 错题本（记录用户理解薄弱点）
* 主动复习（间隔重复）
* 多老师 Persona（教授/学长/幽默老师）
* 自动生成课程大纲
* 视频关键帧提取（OCR + 多模态）
* 边缘部署：ONNX、4bit 量化、Jetson/工控机适配

---


